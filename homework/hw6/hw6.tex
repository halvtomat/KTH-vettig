\documentclass[11pt, a4paper]{article}

\usepackage{amsmath}

\title{Philosophy of science and consciousness}
\author{Daniel Gustafsson}
\date{November 2021}

\begin{document}
\maketitle

\section{Philosophy of science}

\textit{What is anti-realism?}

Believers of scientific anti-realism think that scientific theories are
only used as tools to make predictions about the results of observations.
They do not necessarily believe that a theory which can be used to make
good predictions is accurate to the truth.

\vspace{2mm}\noindent\textit{Example of non-observable entity.}

A classic example of a non-observable entity is a black hole.
Theoretically, black holes have such a strong gravitational pull that
not even light can escape them. This means that it is impossible to observe
a black hole directly and the only thing we can observe is their influence
on nearby objects.

\vspace{2mm}\noindent\textit{Why science is meaningful}

Whether a scientific theory is true or not is not relevant to whether it
is useful or not. If a scientific theory can be used to accurately predict
results then it is useful.

\section{Consciousness}

In the Chinese Room Argument \cite{cra}, Searle claims that the brain's mind isn't
a computer program and can't be replicated by a machine. I don't agree with this
argument. I don't believe that the mental contents of my brain is decided by some
magic, I believe that they are decided by my memories and experiences and probably
in some way by my genes.

Based on this, I also think that any mind, given the same genes, memories and
experiences, would have the same mental contents as my own.
This leads me to believe that there is some complex syntax which given an input
of memories, experiences and genes would output some mental contents. Meaning that
mental contents and semantics are merely a product of syntax.

Since machines are fully capable of running programs given some syntax, I believe
that a machine could fully simulate and possess a mind.

I do however believe that the Chinese Room Argument demonstrates flaws in the
Turing test. It is correct that a book of rules on which Chinese symbols to
output given a Chinese symbol input would pass the Turing test given a large
enough rule book or being asked the right questions. But what happens if a 
combination of Chinese symbols comes in which there isn't a rule for in the 
book? Surely a combination of that kind must exist, otherwise the rule book
would be infinite. If the book can't be infinite, there must be a program 
corresponding to that book and that program would pass the Turing test.
More importantly, If the rule book could be large enough that all reasonable
input combinations have some corresponding output combination then what is
there to say that all the human mind really is is just a large rule book?
How can a person really know that someone else actually possesses some semantics
and that they are not just internally reading a rule and outputting the answer
without actually understanding? How can a person even know that their own mind
is not just following some rule book subconsciously?

This is my take on the Chinese Room Argument.


\bibliographystyle{amsplain}
\bibliography{hw6.bib}

\end{document}